{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"it caught him off guard that space smelled of seared steak\",\n",
    "    \"she could not decide between painting her teeth or brushing her nails\",\n",
    "    \"he thought there'd be sufficient time is he hid his watch\",\n",
    "    \"the bees decided to have a mutiny against their queen\",\n",
    "    \"the sign said there was road work ahead so she decided to speed up\",\n",
    "    \"on a scale of one to ten, what's your favorite flavor of color?\",\n",
    "    \"flying stinging insects rebelled in opposition to the matriarch\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(sentences)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "scores = cos_sim(embeddings[-1], embeddings[:-1])\n",
    "\n",
    "print(sentences[-1])\n",
    "for i, score in enumerate(scores[0]):\n",
    "    print(f\"{round(score.item(), 4)} | {sentences[i]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer, \\\n",
    "                         DPRQuestionEncoder, DPRQuestionEncoderTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_model = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "\n",
    "question_model = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"what is the capital city of australia?\",\n",
    "    \"what is the best selling sci-fi book?\",\n",
    "    \"how many searches are performed on Google?\"\n",
    "]\n",
    "\n",
    "contexts = [\n",
    "    \"canberra is the capital city of australia\",\n",
    "    \"what is the capital city of australia?\",\n",
    "    \"the capital city of france is paris\",\n",
    "    \"what is the best selling sci-fi book?\",\n",
    "    \"sc-fi is a popular book genre read by millions\",\n",
    "    \"the best-selling sci-fi book is dune\",\n",
    "    \"how many searches are performed on Google?\",\n",
    "    \"Google serves more than 2 trillion queries annually\",\n",
    "    \"Google is a popular search engine\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb_tokens = ctx_tokenizer(contexts, max_length=256, padding='max_length',\n",
    "                          truncation=True, return_tensors='pt')\n",
    "xb = ctx_model(**xb_tokens)\n",
    "\n",
    "xq_tokens = question_tokenizer(questions, max_length=256, padding='max_length',\n",
    "                               truncation=True, return_tensors='pt')\n",
    "xq = question_model(**xq_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb.pooler_output.shape, xq.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, xq_vector in enumerate(xq.pooler_output):\n",
    "    probs = cos_sim(xq_vector, xb.pooler_output)\n",
    "    argmax = torch.argmax(probs)\n",
    "\n",
    "    print(questions[i])\n",
    "    print(contexts[argmax])\n",
    "    print('---------------')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://images.unsplash.com/photo-1576201836106-db1758fd1c97?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=400&q=80\",\n",
    "    \"https://images.unsplash.com/photo-1591294100785-81d39c061468?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=300&q=80\",\n",
    "    \"https://images.unsplash.com/photo-1548199973-03cce0bbc87b?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=400&q=80\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\n",
    "    Image.open(requests.get(url, stream=True).raw) for url in urls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    plt.show(plt.imshow(np.asarray(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = [\"a dog hiding behind a tree\",\n",
    "            \"one white and another multi color dogs running\",\n",
    "            \"two different breed dogs are running\",            \n",
    "            \"two dog running like a horse\",          \n",
    "            \"a dog running over green grass\",\n",
    "            \"a cucumber on a tree\",\n",
    "            \"trees in the park\",\n",
    "            \"a cucumber dog\"]\n",
    "\n",
    "inputs = processor(\n",
    "    text=captions, images=images,\n",
    "    return_tensors='pt', padding=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)\n",
    "probs = outputs.logits_per_image.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in enumerate(images):\n",
    "    argmax = probs[i].item()\n",
    "    print(captions[argmax])\n",
    "    plt.show(plt.imshow(np.asarray(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
