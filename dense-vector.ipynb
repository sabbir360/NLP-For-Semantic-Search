{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting torch>=1.6.0 (from sentence-transformers)\n",
      "  Using cached torch-2.0.1-cp311-cp311-win_amd64.whl (172.3 MB)\n",
      "Collecting torchvision (from sentence-transformers)\n",
      "  Using cached torchvision-0.15.2-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Collecting numpy (from sentence-transformers)\n",
      "  Using cached numpy-1.24.3-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.2.2-cp311-cp311-win_amd64.whl (8.3 MB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.10.1-cp311-cp311-win_amd64.whl (42.2 MB)\n",
      "Collecting nltk (from sentence-transformers)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting sentencepiece (from sentence-transformers)\n",
      "  Using cached sentencepiece-0.1.99-cp311-cp311-win_amd64.whl (977 kB)\n",
      "Collecting huggingface-hub>=0.4.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.4.0->sentence-transformers)\n",
      "  Using cached filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting fsspec (from huggingface-hub>=0.4.0->sentence-transformers)\n",
      "  Using cached fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\sabbi\\.env\\jupyter\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.30.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sabbi\\.env\\jupyter\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.4.0->sentence-transformers)\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sabbi\\.env\\jupyter\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Collecting sympy (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sabbi\\.env\\jupyter\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sabbi\\.env\\jupyter\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
      "  Using cached regex-2023.5.5-cp311-cp311-win_amd64.whl (267 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.13.3-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "Collecting click (from nltk->sentence-transformers)\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting joblib (from nltk->sentence-transformers)\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->sentence-transformers)\n",
      "  Using cached Pillow-9.5.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sabbi\\.env\\jupyter\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sabbi\\.env\\jupyter\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sabbi\\.env\\jupyter\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sabbi\\.env\\jupyter\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sabbi\\.env\\jupyter\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.5.7)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.6.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tokenizers, sentencepiece, mpmath, typing-extensions, tqdm, threadpoolctl, sympy, regex, pillow, numpy, networkx, joblib, fsspec, filelock, click, torch, scipy, nltk, huggingface-hub, transformers, torchvision, scikit-learn, sentence-transformers\n",
      "Successfully installed click-8.1.3 filelock-3.12.0 fsspec-2023.5.0 huggingface-hub-0.14.1 joblib-1.2.0 mpmath-1.3.0 networkx-3.1 nltk-3.8.1 numpy-1.24.3 pillow-9.5.0 regex-2023.5.5 scikit-learn-1.2.2 scipy-1.10.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 sympy-1.12 threadpoolctl-3.1.0 tokenizers-0.13.3 torch-2.0.1 torchvision-0.15.2 tqdm-4.65.0 transformers-4.29.1 typing-extensions-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"it caught him off guard that space smelled of seared steak\",\n",
    "    \"she could not decide between painting her teeth or brushing her nails\",\n",
    "    \"he thought there'd be sufficient time is he hid his watch\",\n",
    "    \"the bees decided to have a mutiny against their queen\",\n",
    "    \"the sign said there was road work ahead so she decided to speed up\",\n",
    "    \"on a scale of one to ten, what's your favorite flavor of color?\",\n",
    "    \"flying stinging insects rebelled in opposition to the matriarch\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.encode(sentences)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flying stinging insects rebelled in opposition to the matriarch\n",
      "0.1232 | it caught him off guard that space smelled of seared steak\n",
      "0.1967 | she could not decide between painting her teeth or brushing her nails\n",
      "0.0523 | he thought there'd be sufficient time is he hid his watch\n",
      "0.6084 | the bees decided to have a mutiny against their queen\n",
      "0.1011 | the sign said there was road work ahead so she decided to speed up\n",
      "-0.0492 | on a scale of one to ten, what's your favorite flavor of color?\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "scores = cos_sim(embeddings[-1], embeddings[:-1])\n",
    "\n",
    "print(sentences[-1])\n",
    "for i, score in enumerate(scores[0]):\n",
    "    print(f\"{round(score.item(), 4)} | {sentences[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
